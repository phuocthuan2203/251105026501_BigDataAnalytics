{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6717236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/25 09:59:10 WARN Utils: Your hostname, thuan-precision-5560 resolves to a loopback address: 127.0.1.1; using 192.168.1.5 instead (on interface wlp0s20f3)\n",
      "25/09/25 09:59:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/25 09:59:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created new SparkContext\n",
      "‚úÖ SparkContext ready - Version: 3.5.6\n",
      "‚úÖ Application: Lab2_Complete\n"
     ]
    }
   ],
   "source": [
    "# ===== FIXED SETUP FOR JUPYTER =====\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Clear any existing Spark environment variables\n",
    "spark_env_vars = ['SPARK_HOME', 'SPARK_LOCAL_DIRS', 'SPARK_CONF_DIR']\n",
    "for var in spark_env_vars:\n",
    "    if var in os.environ:\n",
    "        del os.environ[var]\n",
    "\n",
    "# Set clean environment\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# Import and create SparkContext (only once!)\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "# Check if SparkContext already exists\n",
    "try:\n",
    "    # Try to access existing SparkContext\n",
    "    sc.version\n",
    "    print(\"‚úÖ Using existing SparkContext\")\n",
    "except:\n",
    "    # Create new SparkContext if none exists\n",
    "    conf = SparkConf().setAppName(\"Lab2_Complete\").setMaster(\"local[*]\")\n",
    "    sc = SparkContext(conf=conf)\n",
    "    print(\"‚úÖ Created new SparkContext\")\n",
    "\n",
    "print(f\"‚úÖ SparkContext ready - Version: {sc.version}\")\n",
    "print(f\"‚úÖ Application: {sc.appName}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "603b3f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== B√ÄI 2: L·ªåC C√ÅC RDD ===\n",
      "\n",
      "Step 1: T·∫°o RDD t·ª´ 0 ƒë·∫øn 9999 v·ªõi 5 ph√¢n v√πng\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RDD ƒë∆∞·ª£c t·∫°o v·ªõi 10000 s·ªë\n",
      "‚úÖ S·ªë ph√¢n v√πng: 5\n",
      "Ph√¢n b·ªï d·ªØ li·ªáu theo ph√¢n v√πng:\n",
      "  Ph√¢n v√πng 0: 2000 s·ªë\n",
      "  Ph√¢n v√πng 1: 2000 s·ªë\n",
      "  Ph√¢n v√πng 2: 2000 s·ªë\n",
      "  Ph√¢n v√πng 3: 2000 s·ªë\n",
      "  Ph√¢n v√πng 4: 2000 s·ªë\n"
     ]
    }
   ],
   "source": [
    "# ===== B√ÄI 2: L·ªåC C√ÅC RDD =====\n",
    "print(\"=== B√ÄI 2: L·ªåC C√ÅC RDD ===\\n\")\n",
    "\n",
    "# T·∫°o RDD t·ª´ 0 ƒë·∫øn 9999 v·ªõi 5 ph√¢n v√πng\n",
    "print(\"Step 1: T·∫°o RDD t·ª´ 0 ƒë·∫øn 9999 v·ªõi 5 ph√¢n v√πng\")\n",
    "rdd_numbers = sc.parallelize(range(10000), 5)\n",
    "\n",
    "print(f\"‚úÖ RDD ƒë∆∞·ª£c t·∫°o v·ªõi {rdd_numbers.count()} s·ªë\")\n",
    "print(f\"‚úÖ S·ªë ph√¢n v√πng: {rdd_numbers.getNumPartitions()}\")\n",
    "\n",
    "# Xem c√°ch ph√¢n chia d·ªØ li·ªáu\n",
    "partitions_info = [(i, len(partition)) for i, partition in enumerate(rdd_numbers.glom().collect())]\n",
    "print(\"Ph√¢n b·ªï d·ªØ li·ªáu theo ph√¢n v√πng:\")\n",
    "for partition_id, count in partitions_info:\n",
    "    print(f\"  Ph√¢n v√πng {partition_id}: {count} s·ªë\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ace51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Hi·ªÉu logic l·ªçc - s·ªë chia h·∫øt cho 3 nh∆∞ng KH√îNG chia h·∫øt cho 9\n",
      "\n",
      "Test logic v·ªõi m·ªôt v√†i s·ªë:\n",
      "S·ªë | Chia h·∫øt cho 3? | Chia h·∫øt cho 9? | K·∫øt qu·∫£ filter\n",
      "-------------------------------------------------------\n",
      " 3 |             1 |             0 | True\n",
      " 6 |             1 |             0 | True\n",
      " 9 |             1 |             1 | False\n",
      "12 |             1 |             0 | True\n",
      "15 |             1 |             0 | True\n",
      "18 |             1 |             1 | False\n",
      "21 |             1 |             0 | True\n",
      "24 |             1 |             0 | True\n",
      "27 |             1 |             1 | False\n",
      "30 |             1 |             0 | True\n",
      "\n",
      "üìù K·∫øt lu·∫≠n: C√°c s·ªë th·ªèa m√£n l√†: [3, 6, 12, 15, 21, 24, 30]\n"
     ]
    }
   ],
   "source": [
    "# ===== HI·ªÇU LOGIC FILTER =====\n",
    "print(\"Step 2: Hi·ªÉu logic l·ªçc - s·ªë chia h·∫øt cho 3 nh∆∞ng KH√îNG chia h·∫øt cho 9\")\n",
    "\n",
    "# Test m·ªôt v√†i s·ªë ƒë·ªÉ hi·ªÉu logic\n",
    "test_numbers = [3, 6, 9, 12, 15, 18, 21, 24, 27, 30]\n",
    "print(\"\\nTest logic v·ªõi m·ªôt v√†i s·ªë:\")\n",
    "print(\"S·ªë | Chia h·∫øt cho 3? | Chia h·∫øt cho 9? | K·∫øt qu·∫£ filter\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for num in test_numbers:\n",
    "    div_by_3 = (num % 3 == 0)\n",
    "    div_by_9 = (num % 9 == 0)\n",
    "    result = div_by_3 and not div_by_9\n",
    "    print(f\"{num:2} | {div_by_3:13} | {div_by_9:13} | {result}\")\n",
    "\n",
    "print(f\"\\nüìù K·∫øt lu·∫≠n: C√°c s·ªë th·ªèa m√£n l√†: {[n for n in test_numbers if n%3==0 and n%9!=0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecfbc7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: √Åp d·ª•ng filter v·ªõi lambda function\n",
      "‚úÖ Filter ƒë√£ ƒë∆∞·ª£c √°p d·ª•ng (ƒë√¢y l√† transformation - lazy evaluation)\n",
      "üí° Ch∆∞a c√≥ t√≠nh to√°n th·ª±c s·ª± x·∫£y ra cho ƒë·∫øn khi c√≥ action\n",
      "\n",
      "Counting filtered elements (this triggers computation)...\n",
      "‚úÖ S·ªë ph·∫ßn t·ª≠ sau khi l·ªçc: 2222\n",
      "üìä Verification:\n",
      "  - S·ªë chia h·∫øt cho 3: 3334\n",
      "  - S·ªë chia h·∫øt cho 9: 1112\n",
      "  - K·∫øt qu·∫£ mong ƒë·ª£i: 2222\n",
      "  - K·∫øt qu·∫£ th·ª±c t·∫ø: 2222\n",
      "  - ƒê√∫ng? ƒê√∫ng ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# ===== √ÅP D·ª§NG FILTER =====\n",
    "print(\"Step 3: √Åp d·ª•ng filter v·ªõi lambda function\")\n",
    "\n",
    "# √Åp d·ª•ng filter\n",
    "filtered_rdd = rdd_numbers.filter(lambda n: n % 3 == 0 and n % 9 != 0)\n",
    "\n",
    "print(\"‚úÖ Filter ƒë√£ ƒë∆∞·ª£c √°p d·ª•ng (ƒë√¢y l√† transformation - lazy evaluation)\")\n",
    "print(\"üí° Ch∆∞a c√≥ t√≠nh to√°n th·ª±c s·ª± x·∫£y ra cho ƒë·∫øn khi c√≥ action\")\n",
    "\n",
    "# ƒê·∫øm s·ªë ph·∫ßn t·ª≠ sau khi filter (ƒë√¢y l√† action - s·∫Ω trigger computation)\n",
    "print(\"\\nCounting filtered elements (this triggers computation)...\")\n",
    "filtered_count = filtered_rdd.count()\n",
    "print(f\"‚úÖ S·ªë ph·∫ßn t·ª≠ sau khi l·ªçc: {filtered_count}\")\n",
    "\n",
    "# T√≠nh to√°n ƒë·ªÉ so s√°nh\n",
    "total_div_by_3 = len([n for n in range(10000) if n % 3 == 0])  # Divisible by 3\n",
    "total_div_by_9 = len([n for n in range(10000) if n % 9 == 0])  # Divisible by 9\n",
    "expected_result = total_div_by_3 - total_div_by_9\n",
    "\n",
    "print(f\"üìä Verification:\")\n",
    "print(f\"  - S·ªë chia h·∫øt cho 3: {total_div_by_3}\")\n",
    "print(f\"  - S·ªë chia h·∫øt cho 9: {total_div_by_9}\")\n",
    "print(f\"  - K·∫øt qu·∫£ mong ƒë·ª£i: {expected_result}\")\n",
    "print(f\"  - K·∫øt qu·∫£ th·ª±c t·∫ø: {filtered_count}\")\n",
    "print(f\"  - ƒê√∫ng? {'ƒê√∫ng ‚úÖ' if filtered_count == expected_result else 'Sai ‚ùå'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44a0c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Xem k·∫øt qu·∫£ theo t·ª´ng ph√¢n v√πng\n",
      "K·∫øt qu·∫£ l·ªçc theo t·ª´ng ph√¢n v√πng:\n",
      "Ph√¢n v√πng 0: 444 s·ªë\n",
      "  First 10: [3, 6, 12, 15, 21, 24, 30, 33, 39, 42]\n",
      "  Last 10:  [1956, 1959, 1965, 1968, 1974, 1977, 1983, 1986, 1992, 1995]\n",
      "\n",
      "Ph√¢n v√πng 1: 445 s·ªë\n",
      "  First 10: [2001, 2004, 2010, 2013, 2019, 2022, 2028, 2031, 2037, 2040]\n",
      "  Last 10:  [3957, 3963, 3966, 3972, 3975, 3981, 3984, 3990, 3993, 3999]\n",
      "\n",
      "Ph√¢n v√πng 2: 444 s·ªë\n",
      "  First 10: [4002, 4008, 4011, 4017, 4020, 4026, 4029, 4035, 4038, 4044]\n",
      "  Last 10:  [5955, 5961, 5964, 5970, 5973, 5979, 5982, 5988, 5991, 5997]\n",
      "\n",
      "Ph√¢n v√πng 3: 445 s·ªë\n",
      "  First 10: [6000, 6006, 6009, 6015, 6018, 6024, 6027, 6033, 6036, 6042]\n",
      "  Last 10:  [7959, 7962, 7968, 7971, 7977, 7980, 7986, 7989, 7995, 7998]\n",
      "\n",
      "Ph√¢n v√πng 4: 444 s·ªë\n",
      "  First 10: [8004, 8007, 8013, 8016, 8022, 8025, 8031, 8034, 8040, 8043]\n",
      "  Last 10:  [9957, 9960, 9966, 9969, 9975, 9978, 9984, 9987, 9993, 9996]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== XEM K·∫æT QU·∫¢ THEO PH√ÇN V√ôNG =====\n",
    "print(\"Step 4: Xem k·∫øt qu·∫£ theo t·ª´ng ph√¢n v√πng\")\n",
    "\n",
    "# L·∫•y k·∫øt qu·∫£ theo ph√¢n v√πng\n",
    "partitioned_results = filtered_rdd.glom().collect()\n",
    "\n",
    "print(\"K·∫øt qu·∫£ l·ªçc theo t·ª´ng ph√¢n v√πng:\")\n",
    "for partition_id, partition_data in enumerate(partitioned_results):\n",
    "    print(f\"Ph√¢n v√πng {partition_id}: {len(partition_data)} s·ªë\")\n",
    "    if len(partition_data) > 0:\n",
    "        print(f\"  First 10: {partition_data[:10]}\")\n",
    "        print(f\"  Last 10:  {partition_data[-10:]}\")\n",
    "    else:\n",
    "        print(f\"  (empty partition)\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f72664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: L∆∞u k·∫øt qu·∫£ v√†o th∆∞ m·ª•c\n",
      "Saving results to: ../../results/Bai2\n",
      "‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o file\n",
      "\n",
      "C√°c file ƒë∆∞·ª£c t·∫°o trong ../../results/Bai2:\n",
      "  üìÑ ._SUCCESS.crc (8 bytes)\n",
      "  üìÑ .part-00000.crc (24 bytes)\n",
      "  üìÑ .part-00001.crc (28 bytes)\n",
      "  üìÑ .part-00002.crc (28 bytes)\n",
      "  üìÑ .part-00003.crc (28 bytes)\n",
      "  üìÑ .part-00004.crc (28 bytes)\n",
      "  üìÑ _SUCCESS (0 bytes)\n",
      "  üìÑ part-00000 (1974 bytes)\n",
      "  üìÑ part-00001 (2225 bytes)\n",
      "  üìÑ part-00002 (2220 bytes)\n",
      "  üìÑ part-00003 (2225 bytes)\n",
      "  üìÑ part-00004 (2220 bytes)\n"
     ]
    }
   ],
   "source": [
    "# ===== L∆ØU K·∫æT QU·∫¢ V√ÄO FILE =====\n",
    "print(\"Step 5: L∆∞u k·∫øt qu·∫£ v√†o th∆∞ m·ª•c\")\n",
    "\n",
    "import os\n",
    "\n",
    "# T·∫°o output directory\n",
    "output_path = \"../../results/Bai2\"\n",
    "print(f\"Saving results to: {output_path}\")\n",
    "\n",
    "# X√≥a th∆∞ m·ª•c output c≈© n·∫øu t·ªìn t·∫°i (Spark y√™u c·∫ßu output directory kh√¥ng t·ªìn t·∫°i)\n",
    "import shutil\n",
    "if os.path.exists(output_path):\n",
    "    shutil.rmtree(output_path)\n",
    "    print(\"‚úÖ ƒê√£ x√≥a th∆∞ m·ª•c output c≈©\")\n",
    "\n",
    "# L∆∞u RDD v√†o file\n",
    "filtered_rdd.saveAsTextFile(output_path)\n",
    "print(\"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o file\")\n",
    "\n",
    "# Ki·ªÉm tra c√°c file ƒë∆∞·ª£c t·∫°o\n",
    "if os.path.exists(output_path):\n",
    "    files = os.listdir(output_path)\n",
    "    print(f\"\\nC√°c file ƒë∆∞·ª£c t·∫°o trong {output_path}:\")\n",
    "    for file in sorted(files):\n",
    "        file_path = os.path.join(output_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            size = os.path.getsize(file_path)\n",
    "            print(f\"  üìÑ {file} ({size} bytes)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
